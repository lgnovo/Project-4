{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "\n",
    "#K-means algorithm (finding K method 1)\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#PCA finding K (finding K method 2)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#dependencies for K-Nearest Neighbors (KNN) Machine learning\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#each time it says a standalone \"df\", plz replace w the dataframe we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-means algorithm\n",
    "#identifies clusters from a multidimensional standpt, which isn't totally linear and can point in the direction of influencing variables\n",
    "\n",
    "#create a list for inertia and values of K\n",
    "inertia = []\n",
    "k = list(range(1, 5))\n",
    "\n",
    "#for loop for K-means algorithm\n",
    "for i in k:\n",
    "    k_model = KMeans(n_clusters=i, random_state=1)\n",
    "    k_model.fit(df)\n",
    "    inertia.append(k_model.inertia_)\n",
    "\n",
    "#dictionary (variable) for elbow method data\n",
    "elbowK_data = {\"k\": k, \"inertia\": inertia}\n",
    "    #convert to df named df_elbowK\n",
    "df_elbowK = pd.DataFrame(elbowK_data)\n",
    "\n",
    "#plot it to find the best K - visually look at the plot and find K with the elbow method\n",
    "df_elbowK.hvplot.line(\n",
    "    x=\"k\", \n",
    "    y=\"inertia\", \n",
    "    title=\"Elbow Curve\", \n",
    "    xticks=k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA - turning multidimensional into a 2-dimensional analysis here.\n",
    "#reduces dimensionality overall to show a linear (2d) relationship btwn variables\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "rename_this_PCA = pca.fit_transform(df)\n",
    "\n",
    "#turn it from an array into a df\n",
    "newPCAdf = pd.DataFrame(\n",
    "    rename_this_PCA,\n",
    "    columns=[\"PCA1\", \"PCA2\"]\n",
    ")\n",
    "\n",
    "#store inertia values and set the min and max k clusters\n",
    "inertia = []\n",
    "k = list(range(1, 5))\n",
    "\n",
    "for i in k:\n",
    "    k_model = KMeans(n_clusters=i, random_state=1)\n",
    "    k_model.fit(newPCAdf)\n",
    "    inertia.append(k_model.inertia_)\n",
    "\n",
    "#turn it into a df named df_elbowPCA\n",
    "elbowPCA_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbowPCA = pd.DataFrame(elbowPCA_data)\n",
    "\n",
    "#plot it to find the best K - visually look at the plot and find K with the elbow method\n",
    "df_elbowPCA.hvplot.line(\n",
    "    x=\"k\", \n",
    "    y=\"inertia\", \n",
    "    title=\"Elbow Curve\", \n",
    "    xticks=k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the K value plots\n",
    "#K-means algorithm: # of groups with all dimensions considered\n",
    "#PCA: # of groups with dimensions boiled down to 2 for 2d grouping (lil more vague)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Machine Learning\n",
    "#algorithm stores the entire training dataset in memory\n",
    "\n",
    "    #Predicts by\n",
    "#Calculating dif btwn the new data point and all points in the training dataset\n",
    "#Identifies K nearest neighbors (data points) to the new data point based on distance\n",
    "#Predicts new data point by taking the average or weighted average of the values of its K nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Machine Learning pt 1\n",
    "\n",
    "#isolate Attrition status (flag?) as y variable\n",
    "y = df['flag']\n",
    "X = df.drop(columns='flag')\n",
    "    #convert categorical x variables to binary\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "#set training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "#scale the (now all) numerical values so there aren't extremes, easy computation\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "    #SET K VALUE FOUND FROM ABOVE WHERE IT SAYS 00\n",
    "model = KNeighborsClassifier(n_neighbors=00)\n",
    "\n",
    "#train the model\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Machine Learning pt 2\n",
    "\n",
    "#make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "#print the confusion matrix\n",
    "confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Machine Learning pt 3\n",
    "\n",
    "#Classification Report\n",
    "    #Precision = accuracy of positive predictions made by the model. \n",
    "        #\"Of all the instances predicted as positive, how many are actually positive?\"\n",
    "        #high precision = low false positive rate (less false alarms)\n",
    "    #Recall/sensitivity/true positive rate (TPR) = ability to correctly identify positive instances from all actual positive instances in the dataset.\n",
    "        #\"Of all the actual positive instances, how many did the model correctly identify?\" \n",
    "        #high recall = low false negative rate \n",
    "        #F-1 = harmonic mean of precision and recall, balances both precision and recall (overall rating of model performance)\n",
    "\n",
    "print(classification_report(y_pred,y_test))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
